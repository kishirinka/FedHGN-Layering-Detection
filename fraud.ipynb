{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "T7yz565SSTPv"
      },
      "outputs": [],
      "source": [
        "# # 1. Uninstall\n",
        "# !pip uninstall -y dgl torch torchdata numpy\n",
        "\n",
        "# # 2. Install versi spesifik numpy dulu\n",
        "# !pip install numpy==1.26.4\n",
        "\n",
        "# # 3. Install versi Torch + torchvision + torchaudio\n",
        "# !pip install torch==2.1.1 torchvision==0.16.1 torchaudio==2.1.1\n",
        "\n",
        "# # 4. Install DGL yang sesuai\n",
        "# !pip install dgl==2.1.0\n",
        "\n",
        "# # 5. Install library tambahan\n",
        "# !pip install torchdata==0.6.1 scikit-learn scipy pyyaml tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "2COU_u2iB5x5"
      },
      "outputs": [],
      "source": [
        "# # UNINSTALL torchdata (kalau ada), install versi yang cocok\n",
        "# !pip uninstall -y torchdata\n",
        "\n",
        "# # Install ulang torchdata yang COCOK dengan torch 2.1.1 (versi 0.6.1 TIDAK COCOK)\n",
        "# # Install versi torchdata 0.11.0\n",
        "# !pip install torchdata==0.11.0\n",
        "\n",
        "# # Install DGL 2.1.0 (cocok dengan torch 2.1.1 dan torchdata 0.11.0)\n",
        "# !pip install dgl==2.1.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "ii7LHhCtCII0"
      },
      "outputs": [],
      "source": [
        "# # UNINSTALL semua dulu\n",
        "# # !pip uninstall -y dgl dgl-cu12 torch torchdata torchaudio torchvision\n",
        "\n",
        "\n",
        "\n",
        "# # PASANG versi yang kompatibel (Python 3.11 dan DGL 2.1.0)\n",
        "# !pip install torch==2.1.1 torchvision==0.16.1 torchaudio==2.1.1\n",
        "# !pip install torchdata==0.6.1  # << Versi INI yang sudah terbukti cocok dengan torch==2.1.1\n",
        "# !pip install dgl==2.1.0  # atau dgl-cu12==2.1.0 jika pakai GPU CUDA 12\n",
        "# # 2. Install versi spesifik numpy dulu\n",
        "# # !pip install numpy==1.26.4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h42kxn67CMcc",
        "outputId": "fd75f839-55eb-4d8e-891a-ac5057ba7891"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 2.0.1+cu117\n",
            "DGL version: 2.1.0\n",
            "TorchData version: 0.6.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import dgl\n",
        "import torchdata\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)         # 2.1.1\n",
        "print(\"DGL version:\", dgl.__version__)             # 2.1.0\n",
        "print(\"TorchData version:\", torchdata.__version__) # 0.11.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "0VlmYdqPT1z0"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import shutil\n",
        "from argparse import Namespace\n",
        "from pathlib import Path\n",
        "from typing import Optional, Callable\n",
        "\n",
        "import numpy as np\n",
        "import torch as th\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import yaml\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "LcsPp8vGTtos"
      },
      "outputs": [],
      "source": [
        "# Load masing-masing graph dari file\n",
        "g1, _ = dgl.load_graphs(\"graph_bank_0.bin\")\n",
        "g2, _ = dgl.load_graphs(\"graph_bank_11.bin\")\n",
        "g3, _ = dgl.load_graphs(\"graph_bank_12.bin\")\n",
        "g4, _ = dgl.load_graphs(\"graph_bank_20.bin\")\n",
        "g5, _ = dgl.load_graphs(\"graph_bank_27.bin\")\n",
        "\n",
        "# Gabungkan semua graph ke dalam 1 list\n",
        "g_list = g1 + g2 + g3 + g4 + g5\n",
        "\n",
        "# Tentukan jumlah kelas (misalnya binary classification = 2 kelas)\n",
        "label_dict = {\"num_classes\": torch.tensor([2])}\n",
        "\n",
        "# Simpan sebagai 1 file .bin yang sesuai format FedHGN\n",
        "dgl.save_graphs(\"aml-hetero_random-edges_5.bin\", g_list, labels=label_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "094ob42BRCVB"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_configs(args):\n",
        "    with open(args.config_path) as f:\n",
        "        configs = yaml.load(f, Loader=yaml.FullLoader)\n",
        "\n",
        "    dataset_configs = configs[\"datasets\"][args.dataset]\n",
        "    dataset_cname = dataset_configs.pop(\"cname\")\n",
        "    dataset_path = dataset_configs.pop(\"path\")\n",
        "    if dataset_configs[\"task\"] == \"node_classification\":\n",
        "        task_literal = \"nc\"\n",
        "    else:\n",
        "        raise ValueError(\"Unknown task type: {}\".format(dataset_configs[\"task\"]))\n",
        "    model_configs = configs[\"models\"].get(f\"{args.model}_{task_literal}\", configs[\"models\"][args.model])\n",
        "    framework_configs = configs[\"frameworks\"].get(f\"{args.framework}_{task_literal}\",\n",
        "                                                  configs[\"frameworks\"][args.framework])\n",
        "\n",
        "    if args.framework == \"Central\":\n",
        "        args.split_strategy = \"centralized\"\n",
        "        args.num_clients = 1\n",
        "    if args.framework != \"FedHGN\":\n",
        "        args.ablation = None\n",
        "    assert args.split_strategy in [\"centralized\", \"edges\", \"etypes\"]\n",
        "    if args.split_strategy in [\"edges\", \"etypes\"]:\n",
        "        args.split_strategy = f\"random-{args.split_strategy}\"\n",
        "\n",
        "    all_configs = vars(args) | dataset_configs | model_configs | framework_configs\n",
        "    all_configs[\"dataset_cname\"] = dataset_cname\n",
        "    all_configs[\"dataset_path\"] = dataset_path\n",
        "\n",
        "    return Namespace(**all_configs)\n",
        "\n",
        "\n",
        "def get_save_path(args, prefix=\"./saves\"):\n",
        "    save_path = Path(prefix, args.framework if args.ablation is None else f\"{args.framework}_{args.ablation}\",\n",
        "                     args.model, f\"{args.dataset}_{args.split_strategy}_{args.num_clients}\")\n",
        "    save_path.mkdir(parents=True, exist_ok=True)\n",
        "    old_saves = [int(str(x.name)) for x in save_path.iterdir() if x.is_dir() and str(x.name).isdigit()]\n",
        "    if len(old_saves) == 0:\n",
        "        save_num = 1\n",
        "    else:\n",
        "        save_num = max(old_saves) + 1\n",
        "    save_path = save_path / str(save_num)\n",
        "    save_path.mkdir()\n",
        "\n",
        "    # copy config files to the save dir\n",
        "    shutil.copy(\"./configs.yaml\", save_path)\n",
        "\n",
        "    return str(save_path)\n",
        "\n",
        "\n",
        "def set_random_seeds(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    th.manual_seed(seed)\n",
        "\n",
        "\n",
        "def get_data_dict(data, types):\n",
        "    if len(types) == 1:\n",
        "        assert not isinstance(data, dict)\n",
        "        return {types[0]: data}\n",
        "    else:\n",
        "        assert isinstance(data, dict)\n",
        "        return data\n",
        "\n",
        "\n",
        "def align_schemas(g_list):\n",
        "    ntypes = []\n",
        "    etypes = []\n",
        "    canonical_etypes = []\n",
        "    for g in g_list:\n",
        "        ntypes.extend(g.ntypes)\n",
        "        etypes.extend(g.etypes)\n",
        "        canonical_etypes.extend(g.canonical_etypes)\n",
        "    ntypes = list(set(ntypes))\n",
        "    etypes = list(set(etypes))\n",
        "    canonical_etypes = list(set(canonical_etypes))\n",
        "    return ntypes, etypes, canonical_etypes\n",
        "\n",
        "\n",
        "def print_results(results: dict[str, float]):\n",
        "    print(\"\\t\".join(results.keys()))\n",
        "    print(\"\\t\".join([f\"{v:.4f}\" for v in results.values()]))\n",
        "\n",
        "\n",
        "def save_results(results: dict[str, float], save_path: str):\n",
        "    save_path = Path(save_path)\n",
        "    with save_path.joinpath(\"results.txt\").open(\"w\") as f:\n",
        "        f.write(\"\\t\".join(results.keys()) + \"\\n\")\n",
        "        f.write(\"\\t\".join([f\"{v:.4f}\" for v in results.values()]) + \"\\n\")\n",
        "\n",
        "\n",
        "def evaluate_node_classification(encoder, decoder, dataloader, target_ntype, return_preds=False):\n",
        "    results = {}\n",
        "    logits_list = []\n",
        "    y_true_list = []\n",
        "\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "    with th.no_grad():\n",
        "        for iteration, (input_nodes, output_nodes, blocks) in enumerate(dataloader):\n",
        "            input_features = get_data_dict(blocks[0].srcdata[\"x\"], blocks[0].srctypes)\n",
        "            output_labels = get_data_dict(blocks[-1].dstdata[\"y\"], blocks[-1].dsttypes)\n",
        "\n",
        "            h_dict = encoder(blocks, input_features)\n",
        "            logits = decoder(h_dict[target_ntype])\n",
        "\n",
        "            logits_list.append(logits.cpu().numpy())\n",
        "            y_true_list.append(output_labels[target_ntype].cpu().numpy())\n",
        "\n",
        "    logits = np.concatenate(logits_list, axis=0)\n",
        "    y_true = np.concatenate(y_true_list, axis=0)\n",
        "\n",
        "    y_pred = np.argmax(logits, axis=-1)\n",
        "    y_score = softmax(logits, axis=-1)\n",
        "\n",
        "    results[\"accuracy\"] = accuracy_score(y_true, y_pred)\n",
        "    results[\"macro-f1\"] = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    results[\"micro-f1\"] = f1_score(y_true, y_pred, average=\"micro\")\n",
        "\n",
        "    if return_preds:\n",
        "        return results, y_true, y_pred\n",
        "    else:\n",
        "        return results\n",
        "\n",
        "\n",
        "\n",
        "def load_data(args):\n",
        "    if args.task == \"node_classification\":\n",
        "        if args.dataset in [\"AML\"]:\n",
        "            load_path = Path(args.dataset_path, f\"{args.dataset_cname}_{args.split_strategy}_{args.num_clients}.bin\")\n",
        "            g_list, label_dict = dgl.load_graphs(str(load_path))\n",
        "\n",
        "            g_list = [g.long() for g in g_list]\n",
        "            for g in g_list:\n",
        "                g.ndata[\"y\"] = g.ndata[\"label\"]\n",
        "                g.ndata[\"x\"] = g.ndata[dgl.NID]  # dummy node feature, will not be used\n",
        "\n",
        "            out_dim = label_dict[\"num_classes\"][0].item()\n",
        "\n",
        "            train_nid_dict_list = [\n",
        "                {ntype: train_mask.nonzero().flatten() for ntype, train_mask in g.ndata[\"train_mask\"].items()} for g in\n",
        "                g_list]\n",
        "            val_nid_dict_list = [\n",
        "                {ntype: val_mask.nonzero().flatten() for ntype, val_mask in g.ndata[\"val_mask\"].items()} for g in\n",
        "                g_list]\n",
        "            test_nid_dict_list = [\n",
        "                {ntype: test_mask.nonzero().flatten() for ntype, test_mask in g.ndata[\"test_mask\"].items()} for g in\n",
        "                g_list]\n",
        "        else:\n",
        "            raise ValueError(\"Unknown dataset of task {}: {}\".format(args.task, args.dataset))\n",
        "        return g_list, out_dim, train_nid_dict_list, val_nid_dict_list, test_nid_dict_list\n",
        "    else:\n",
        "        raise ValueError(\"Unknown task: {}\".format(args.task))\n",
        "\n",
        "def evaluate_local_models_individually(clients):\n",
        "    print(\"Initial Local Evaluation (Before Fed Training)\")\n",
        "    for i, client in enumerate(clients):\n",
        "        results = client.local_evaluate(is_test=True)\n",
        "        print(f\"Client {i} initial evaluation:\")\n",
        "        print_results(results)\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation score/loss doesn't improve after a given patience.\"\"\"\n",
        "\n",
        "    def __init__(self, patience=10, delta=1e-5, mode=\"score\", save_path=\"checkpoint.pt\", verbose=False, ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation score/loss improved.\n",
        "                            Default: 10\n",
        "            verbose (bool): If True, prints a message for each validation score/loss improvement.\n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.delta = delta\n",
        "        self.mode = mode\n",
        "        self.save_path = save_path\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = -np.inf\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, quantity: float, model: Optional[nn.Module] = None, callback: Optional[Callable] = None):\n",
        "        if self.mode == \"score\":\n",
        "            score = quantity\n",
        "        elif self.mode == \"loss\":\n",
        "            score = -quantity\n",
        "        else:\n",
        "            raise ValueError(f\"Invalid mode: {self.mode}\")\n",
        "\n",
        "        if score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.save_checkpoint(quantity, model, callback)\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, quantity: float, model: Optional[nn.Module] = None, callback: Optional[Callable] = None):\n",
        "        \"\"\"Saves model when validation score/loss improves.\"\"\"\n",
        "        if self.verbose:\n",
        "            if self.mode == \"score\":\n",
        "                print(f\"Validation score increased ({self.best_score:.6f} --> {quantity:.6f}).  Saving model ...\")\n",
        "            elif self.mode == \"loss\":\n",
        "                print(f\"Validation loss decreased ({-self.best_score:.6f} --> {quantity:.6f}).  Saving model ...\")\n",
        "            else:\n",
        "                raise ValueError(f\"Invalid mode: {self.mode}\")\n",
        "\n",
        "        if model is not None:\n",
        "            th.save(model.state_dict(), self.save_path)\n",
        "        if callback is not None:\n",
        "            callback(self.save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "7S0Ni7Hlbz0c"
      },
      "outputs": [],
      "source": [
        "class NodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim: int, out_dim: int, pre_activation=F.relu) -> None:\n",
        "        super(NodeClassifier, self).__init__()\n",
        "        self.pre_activation = pre_activation\n",
        "        self.linear = nn.Linear(in_dim, out_dim)\n",
        "\n",
        "    def forward(self, x: th.FloatTensor) -> th.FloatTensor:\n",
        "        return self.linear(self.pre_activation(x)) if self.pre_activation else self.linear(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "p0bg2BApb5cm"
      },
      "outputs": [],
      "source": [
        "\n",
        "from argparse import Namespace\n",
        "from collections.abc import Callable\n",
        "from itertools import chain\n",
        "from typing import Optional, Union\n",
        "\n",
        "import dgl\n",
        "import dgl.nn as dglnn\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RGCNLayer(nn.Module):\n",
        "    def __init__(self, in_dim: int, out_dim: int, etypes: list[str], num_bases: int, *, use_weight: bool = True,\n",
        "                 use_bias: bool = True, activation: Optional[Callable] = None, use_self_loop: bool = False,\n",
        "                 dropout: float = 0.0) -> None:\n",
        "        super(RGCNLayer, self).__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.etypes = etypes\n",
        "        self.num_bases = num_bases\n",
        "        self.use_weight = use_weight\n",
        "        self.use_bias = use_bias\n",
        "        self.activation = activation\n",
        "        self.use_self_loop = use_self_loop\n",
        "\n",
        "        self.conv = dglnn.HeteroGraphConv(\n",
        "            {etype: dglnn.GraphConv(in_dim, out_dim, norm='right', weight=False, bias=False) for etype in etypes})\n",
        "\n",
        "        # always use bases\n",
        "        # basis coefficients are defined in class HGNModel\n",
        "        if self.use_weight:\n",
        "            self.bases = nn.Parameter(th.Tensor(num_bases, in_dim, out_dim))\n",
        "            nn.init.xavier_uniform_(self.bases, gain=nn.init.calculate_gain('relu'))\n",
        "\n",
        "        # bias\n",
        "        if use_bias:\n",
        "            self.h_bias = nn.Parameter(th.Tensor(out_dim))\n",
        "            nn.init.zeros_(self.h_bias)\n",
        "\n",
        "        # weight for self loop\n",
        "        if use_self_loop:\n",
        "            self.loop_weight = nn.Parameter(th.Tensor(in_dim, out_dim))\n",
        "            nn.init.xavier_uniform_(self.loop_weight, gain=nn.init.calculate_gain('relu'))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, g: dgl.DGLHeteroGraph, inputs: dict[str, th.FloatTensor], basis_coeffs: nn.ParameterDict) -> dict[\n",
        "        str, th.FloatTensor]:\n",
        "        with g.local_scope():\n",
        "            if self.use_weight:\n",
        "                # compute the weight matrices from bases and basis coefficients\n",
        "                w_dict = {}\n",
        "                for etype in self.etypes:\n",
        "                    w_dict[etype] = {\n",
        "                        \"weight\": th.matmul(basis_coeffs[etype], self.bases.view(self.num_bases, -1)).view(self.in_dim,\n",
        "                                                                                                           self.out_dim)}\n",
        "            else:\n",
        "                w_dict = {}\n",
        "\n",
        "            if g.is_block:\n",
        "                inputs_src = inputs\n",
        "                inputs_dst = {k: v[:g.number_of_dst_nodes(k)] for k, v in inputs.items()}\n",
        "            else:\n",
        "                inputs_src = inputs_dst = inputs\n",
        "\n",
        "            hs = self.conv(g, inputs, mod_kwargs=w_dict)\n",
        "\n",
        "            def _apply(ntype, h):\n",
        "                if self.use_self_loop:\n",
        "                    h = h + th.matmul(inputs_dst[ntype], self.loop_weight)\n",
        "                if self.use_bias:\n",
        "                    h = h + self.h_bias\n",
        "                if self.activation:\n",
        "                    h = self.activation(h)\n",
        "                return self.dropout(h)\n",
        "\n",
        "            return {ntype: _apply(ntype, h) for ntype, h in hs.items()}\n",
        "\n",
        "\n",
        "class RGCN(nn.Module):\n",
        "    def __init__(self, hidden_dim: int, out_dim: int, etypes: list[str], num_bases: int, *, num_hidden_layers: int = 1,\n",
        "                 dropout: float = 0.0, use_self_loop: bool = False) -> None:\n",
        "        super(RGCN, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.out_dim = out_dim\n",
        "        self.etypes = etypes\n",
        "        self.num_bases = num_bases\n",
        "        self.num_hidden_layers = num_hidden_layers\n",
        "        self.dropout = dropout\n",
        "        self.use_self_loop = use_self_loop\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        # i2h\n",
        "        self.layers.append(RGCNLayer(self.hidden_dim, self.hidden_dim, etypes, self.num_bases, activation=F.relu,\n",
        "                                     use_self_loop=self.use_self_loop, dropout=self.dropout, use_weight=False))\n",
        "        # h2h\n",
        "        for i in range(self.num_hidden_layers):\n",
        "            self.layers.append(RGCNLayer(self.hidden_dim, self.hidden_dim, etypes, self.num_bases, activation=F.relu,\n",
        "                                         use_self_loop=self.use_self_loop, dropout=self.dropout))\n",
        "        # h2o\n",
        "        self.layers.append(RGCNLayer(self.hidden_dim, self.out_dim, etypes, self.num_bases, activation=None,\n",
        "                                     use_self_loop=self.use_self_loop))\n",
        "\n",
        "    def forward(self, g: Union[dgl.DGLHeteroGraph, list], inputs: dict[str, th.FloatTensor],\n",
        "                basis_coeffs_encoder: nn.ModuleList) -> dict[str, th.FloatTensor]:\n",
        "        h = inputs\n",
        "        if isinstance(g, dgl.DGLHeteroGraph):\n",
        "            # full graph\n",
        "            for layer, basis_coeffs in zip(self.layers, chain([None], basis_coeffs_encoder)):\n",
        "                h = layer(g, h, basis_coeffs)\n",
        "        else:\n",
        "            # minibatch\n",
        "            blocks = g\n",
        "            for layer, block, basis_coeffs in zip(self.layers, blocks, chain([None], basis_coeffs_encoder)):\n",
        "                h = layer(block, h, basis_coeffs)\n",
        "        return h\n",
        "\n",
        "\n",
        "class HGNModel(nn.Module):\n",
        "    def __init__(self, args: Namespace, out_dim: int, ntypes: list[str], etypes: list[str],\n",
        "                 canonical_etypes: list[tuple[str, str, str]], num_nodes_dict: dict[str, int]) -> None:\n",
        "        super(HGNModel, self).__init__()\n",
        "        self.model_name = args.model\n",
        "        self.num_bases = args.num_bases\n",
        "        self.ntypes = ntypes\n",
        "        self.etypes = etypes\n",
        "        self.canonical_etypes = canonical_etypes\n",
        "\n",
        "        # embedding layer: private\n",
        "        self.embed_layer = dglnn.HeteroEmbedding(num_nodes_dict, args.hidden_dim)\n",
        "        # self.linear_layer = dglnnHeteroLinear(in_dim_dict, args.hidden_dim)\n",
        "\n",
        "        # HGNN model: shared\n",
        "        if self.model_name == \"RGCN\":\n",
        "            assert args.num_layers > 1\n",
        "            # basis coefficients for relations: private\n",
        "            self.basis_coeffs_encoder = nn.ModuleList()\n",
        "            for _ in range(args.num_layers - 1):\n",
        "                param_dict = nn.ParameterDict()\n",
        "                for etype in self.etypes:\n",
        "                    param_dict[etype] = nn.Parameter(th.Tensor(self.num_bases))\n",
        "                    nn.init.xavier_uniform_(param_dict[etype].view(1, -1), gain=nn.init.calculate_gain('relu'))\n",
        "                self.basis_coeffs_encoder.append(param_dict)\n",
        "            self.model = RGCN(args.hidden_dim, out_dim, etypes, self.num_bases, num_hidden_layers=args.num_layers - 2,\n",
        "                              dropout=args.dropout, use_self_loop=args.use_self_loop)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown model name {self.model_name}\")\n",
        "\n",
        "    def forward(self, g: Union[dgl.DGLHeteroGraph, list], inputs: dict[str, th.FloatTensor]) -> dict[\n",
        "        str, th.FloatTensor]:\n",
        "        # ntype-specific embedding/projection\n",
        "        if isinstance(g, dgl.DGLHeteroGraph):\n",
        "            # full graph\n",
        "            nids_dict = {ntype: g.nodes(ntype) for ntype in g.ntypes}\n",
        "        else:\n",
        "            # minibatch\n",
        "            # g is a list of DGLBlock\n",
        "            nids_dict = get_data_dict(g[0].srcdata[dgl.NID], g[0].srctypes)\n",
        "        h_embed_dict = self.embed_layer(nids_dict)\n",
        "        # h_linear_dict = self.linear_layer(inputs)\n",
        "        # h_dict = h_embed_dict | h_linear_dict\n",
        "        h_dict = h_embed_dict\n",
        "\n",
        "        # HGNN model forward\n",
        "        h_dict = self.model(g, h_dict, self.basis_coeffs_encoder)\n",
        "\n",
        "        return h_dict\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "49D4XOZ7cwho"
      },
      "outputs": [],
      "source": [
        "\n",
        "import random\n",
        "from argparse import Namespace\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "\n",
        "import dgl\n",
        "import torch as th\n",
        "import torch.nn.functional as F\n",
        "import tqdm\n",
        "\n",
        "\n",
        "# FedHGN client\n",
        "class Client:\n",
        "    def __init__(self, args: Namespace, data: tuple, client_id: int) -> None:\n",
        "        self.id = client_id\n",
        "        self.lr = args.lr\n",
        "        self.optim = args.optim\n",
        "        self.weight_decay = args.weight_decay\n",
        "        self.num_local_epochs = args.num_local_epochs\n",
        "        self.align_reg = args.align_reg\n",
        "        self.ablation = args.ablation\n",
        "        self.task = args.task\n",
        "        self.device = args.device\n",
        "\n",
        "        if self.ablation is None:\n",
        "            # set_others_basis_coeffs\n",
        "            self.others_basis_coeffs_encoder = None\n",
        "            self.others_basis_coeffs_decoder = None\n",
        "\n",
        "        # Use GPU-based neighborhood sampling if possible\n",
        "        num_workers = 5 if args.device.type == \"cpu\" else 0\n",
        "        if self.task == \"node_classification\":\n",
        "            g, out_dim, train_nid_dict, val_nid_dict, test_nid_dict = data\n",
        "            self.g = g.to(self.device)\n",
        "            self.ntypes = g.ntypes\n",
        "            self.etypes = list(dict.fromkeys(g.etypes))\n",
        "            self.canonical_etypes = g.canonical_etypes\n",
        "            self.out_dim = out_dim\n",
        "            self.train_nid_dict = {k: v.to(self.device) for k, v in train_nid_dict.items()}\n",
        "            self.val_nid_dict = {k: v.to(self.device) for k, v in val_nid_dict.items()}\n",
        "            self.test_nid_dict = {k: v.to(self.device) for k, v in test_nid_dict.items()}\n",
        "            self.num_nodes_dict = {ntype: g.num_nodes(ntype) for ntype in g.ntypes}\n",
        "            assert len(self.g.ntypes) == 1 or len(self.g.ndata[\"y\"].keys()) == 1\n",
        "            assert len(self.train_nid_dict.keys()) == 1\n",
        "            assert len(self.val_nid_dict.keys()) == 1\n",
        "            assert len(self.test_nid_dict.keys()) == 1\n",
        "\n",
        "            self.target_ntype = list(self.train_nid_dict.keys())[0]\n",
        "\n",
        "            sampler = dgl.dataloading.MultiLayerFullNeighborSampler(args.num_layers)\n",
        "            self.train_dataloader = dgl.dataloading.DataLoader(self.g, self.train_nid_dict, sampler,\n",
        "                                                               batch_size=args.batch_size, shuffle=True,\n",
        "                                                               drop_last=False, num_workers=num_workers,\n",
        "                                                               device=args.device, use_uva=False)\n",
        "            self.val_dataloader = dgl.dataloading.DataLoader(self.g, self.val_nid_dict, sampler,\n",
        "                                                             batch_size=args.batch_size, shuffle=False, drop_last=False,\n",
        "                                                             num_workers=num_workers, device=args.device, use_uva=False)\n",
        "            self.test_dataloader = dgl.dataloading.DataLoader(self.g, self.test_nid_dict, sampler,\n",
        "                                                              batch_size=args.batch_size, shuffle=False,\n",
        "                                                              drop_last=False, num_workers=num_workers,\n",
        "                                                              device=args.device, use_uva=False)\n",
        "            self.encoder = HGNModel(args, args.hidden_dim, self.ntypes, self.etypes, self.canonical_etypes,\n",
        "                                    self.num_nodes_dict)\n",
        "            self.encoder.to(args.device)\n",
        "            self.decoder = NodeClassifier(args.hidden_dim, self.out_dim)\n",
        "            self.decoder.to(args.device)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown task: {}\".format(self.task))\n",
        "\n",
        "    def local_update(self) -> float:\n",
        "        if self.optim == \"Adam\":\n",
        "            optimizer = th.optim.Adam(list(self.encoder.parameters()) + list(self.decoder.parameters()), lr=self.lr,\n",
        "                                      weight_decay=self.weight_decay)\n",
        "        elif self.optim == \"SGD\":\n",
        "            optimizer = th.optim.SGD(list(self.encoder.parameters()) + list(self.decoder.parameters()), lr=self.lr,\n",
        "                                     weight_decay=self.weight_decay)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown optimizer: {}\".format(self.optim))\n",
        "\n",
        "        self.encoder.train()\n",
        "        self.decoder.train()\n",
        "        avg_epoch_loss = 0\n",
        "        with tqdm.tqdm(range(self.num_local_epochs), desc=f\"Client {self.id}\") as tq:\n",
        "            if self.task == \"node_classification\":\n",
        "                for epoch in tq:\n",
        "                    epoch_loss = 0\n",
        "                    num_samples = 0\n",
        "                    for iteration, (input_nodes, output_nodes, blocks) in enumerate(self.train_dataloader):\n",
        "                        input_features = get_data_dict(blocks[0].srcdata[\"x\"], blocks[0].srctypes)\n",
        "                        output_labels = get_data_dict(blocks[-1].dstdata[\"y\"], blocks[-1].dsttypes)\n",
        "\n",
        "                        h_dict = self.encoder(blocks, input_features)\n",
        "                        logits = self.decoder(h_dict[self.target_ntype])\n",
        "                        logp = F.log_softmax(logits, dim=-1)\n",
        "                        batch_loss = F.nll_loss(logp, output_labels[self.target_ntype])\n",
        "                        align_reg_term = self.compute_alignment_regularization() * self.align_reg if self.ablation is None else 0\n",
        "\n",
        "                        optimizer.zero_grad()\n",
        "                        (batch_loss + align_reg_term).backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                        epoch_loss += batch_loss.item() * logits.shape[0]\n",
        "                        num_samples += logits.shape[0]\n",
        "                    epoch_loss /= num_samples\n",
        "                    # print training info\n",
        "                    tq.set_postfix({\"epoch-loss\": f\"{epoch_loss:.4f}\"}, refresh=False)\n",
        "                    avg_epoch_loss += epoch_loss\n",
        "            else:\n",
        "                raise ValueError(\"Unknown task: {}\".format(self.task))\n",
        "\n",
        "        avg_epoch_loss /= self.num_local_epochs\n",
        "        return avg_epoch_loss\n",
        "\n",
        "    def local_evaluate(self, is_test=False, return_preds=False):\n",
        "        \"\"\"Evaluate the model on validation/test set.\"\"\"\n",
        "        self.encoder.eval()\n",
        "        self.decoder.eval()\n",
        "\n",
        "        with th.no_grad():\n",
        "            # Get the correct mask based on evaluation mode\n",
        "            mask_dict = self.test_nid_dict if is_test else self.val_nid_dict\n",
        "            target_ntype = list(mask_dict.keys())[0]  # Get the first/only node type\n",
        "\n",
        "            # Get the dataloader for evaluation\n",
        "            eval_dataloader = self.test_dataloader if is_test else self.val_dataloader\n",
        "\n",
        "            logits_list = []\n",
        "            y_true_list = []\n",
        "\n",
        "            for input_nodes, output_nodes, blocks in eval_dataloader:\n",
        "                # Get input features and output labels\n",
        "                input_features = get_data_dict(blocks[0].srcdata[\"x\"], blocks[0].srctypes)\n",
        "                output_labels = get_data_dict(blocks[-1].dstdata[\"y\"], blocks[-1].dsttypes)\n",
        "\n",
        "                # Forward pass\n",
        "                h_dict = self.encoder(blocks, input_features)\n",
        "                logits = self.decoder(h_dict[target_ntype])\n",
        "\n",
        "                logits_list.append(logits.cpu())\n",
        "                y_true_list.append(output_labels[target_ntype].cpu())\n",
        "\n",
        "            # Concatenate all batches\n",
        "            logits = th.cat(logits_list, dim=0)\n",
        "            y_true = th.cat(y_true_list, dim=0)\n",
        "\n",
        "            # Calculate predictions and metrics\n",
        "            y_pred = logits.argmax(dim=1)\n",
        "            acc = (y_true == y_pred).float().mean().item()\n",
        "            f1_micro = f1_score(y_true, y_pred, average='micro')\n",
        "            f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "            result = {\n",
        "                \"accuracy\": acc,\n",
        "                \"micro-f1\": f1_micro,\n",
        "                \"macro-f1\": f1_macro\n",
        "            }\n",
        "\n",
        "            if return_preds:\n",
        "                return result, y_true.numpy(), y_pred.numpy()\n",
        "            else:\n",
        "                return result\n",
        "\n",
        "\n",
        "    def set_others_basis_coeffs(self, others_basis_coeffs_encoder, others_basis_coeffs_decoder):\n",
        "        if self.ablation is None:\n",
        "            self.others_basis_coeffs_encoder = others_basis_coeffs_encoder\n",
        "            self.others_basis_coeffs_decoder = others_basis_coeffs_decoder\n",
        "        else:\n",
        "            raise AssertionError\n",
        "\n",
        "    def compute_alignment_regularization(self):\n",
        "        reg = 0\n",
        "        # encoder coeffs\n",
        "        local_basis_coeffs_encoder = th.stack(\n",
        "            [th.stack([param for param in param_dict.values()]) for param_dict in self.encoder.basis_coeffs_encoder])\n",
        "        diff = local_basis_coeffs_encoder.unsqueeze(2) - self.others_basis_coeffs_encoder.unsqueeze(1)\n",
        "        min_diff, _ = th.min(th.sum(th.square(diff), dim=-1), dim=-1)\n",
        "        reg += min_diff.sum()\n",
        "        # decoder coeffs\n",
        "        if self.others_basis_coeffs_decoder is not None:\n",
        "            diff = th.stack([v for v in self.decoder.basis_coeffs_decoder.values()], dim=0).unsqueeze(\n",
        "                1) - self.others_basis_coeffs_decoder\n",
        "            min_diff, _ = th.min(th.sum(th.square(diff), dim=-1), dim=-1)\n",
        "            reg += min_diff.sum()\n",
        "        return reg\n",
        "\n",
        "\n",
        "# FedHGN server\n",
        "class Server:\n",
        "    def __init__(self, args: Namespace, ntypes: list[str], etypes: list[str],\n",
        "                 canonical_etypes: list[tuple[str, str, str]], out_dim: Optional[int] = None) -> None:\n",
        "        self.num_clients = args.num_clients\n",
        "        self.ablation = args.ablation\n",
        "        # obtain initial state_dict from a dummy HGNN model\n",
        "        if self.ablation is None or self.ablation == \"B\":\n",
        "            dummy_encoder = HGNModel(args, args.hidden_dim, [\"ntype\"], [\"etype\"], [(\"ntype\", \"etype\", \"ntype\")],\n",
        "                                     {\"ntype\": 1})\n",
        "        else:\n",
        "            dummy_encoder = HGNModel(args, args.hidden_dim, ntypes, etypes, canonical_etypes,\n",
        "                                     {ntype: 1 for ntype in ntypes})\n",
        "        dummy_encoder.to(args.device)\n",
        "        state_dict_encoder = dummy_encoder.state_dict()\n",
        "        # discard the embedding layer\n",
        "        keys_to_remove = []\n",
        "        for key in state_dict_encoder:\n",
        "            if key.startswith(\"embed_layer\"):\n",
        "                keys_to_remove.append(key)\n",
        "        # discard things based on ablation type\n",
        "        if self.ablation is None or self.ablation == \"B\":\n",
        "            # discard the basis coefficients\n",
        "            for key in state_dict_encoder:\n",
        "                if key.startswith(\"basis_coeffs_encoder\"):\n",
        "                    keys_to_remove.append(key)\n",
        "        elif self.ablation == \"C\":\n",
        "            # discard the bases\n",
        "            for key in state_dict_encoder:\n",
        "                if \"bases\" in key:\n",
        "                    keys_to_remove.append(key)\n",
        "        for key in keys_to_remove:\n",
        "            del state_dict_encoder[key]\n",
        "        self.state_dict_encoder = state_dict_encoder\n",
        "\n",
        "        # obtain initial state_dict from a dummy decoder model\n",
        "        if args.task == \"node_classification\":\n",
        "            assert isinstance(out_dim, int)\n",
        "            dummy_decoder = NodeClassifier(args.hidden_dim, out_dim)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown task: {}\".format(args.task))\n",
        "        dummy_decoder.to(args.device)\n",
        "        state_dict_decoder = dummy_decoder.state_dict()\n",
        "        # discard things based on ablation type\n",
        "        keys_to_remove = []\n",
        "        if self.ablation is None or self.ablation == \"B\":\n",
        "            # discard the basis coefficients\n",
        "            for key in state_dict_decoder:\n",
        "                if key.startswith(\"basis_coeffs_decoder\"):\n",
        "                    keys_to_remove.append(key)\n",
        "        elif self.ablation == \"C\":\n",
        "            # discard the bases\n",
        "            for key in state_dict_decoder:\n",
        "                if \"bases\" in key:\n",
        "                    keys_to_remove.append(key)\n",
        "        for key in keys_to_remove:\n",
        "            del state_dict_decoder[key]\n",
        "        self.state_dict_decoder = state_dict_decoder\n",
        "\n",
        "        if self.ablation is None:\n",
        "            # set initial collected coefficients as zeros\n",
        "            self.all_clients_basis_coeffs_encoder = [th.zeros((args.num_layers, 1, args.num_bases), device=args.device)\n",
        "                                                     for _ in range(self.num_clients)]\n",
        "            if args.task == \"node_classification\":\n",
        "                self.all_clients_basis_coeffs_decoder = None\n",
        "            else:\n",
        "                raise ValueError(\"Unknown task: {}\".format(args.task))\n",
        "\n",
        "    def send_model(self, client: Client) -> None:\n",
        "        # send state_dict\n",
        "        client.encoder.load_state_dict(self.state_dict_encoder, strict=False)\n",
        "        client.decoder.load_state_dict(self.state_dict_decoder, strict=False)\n",
        "        if self.ablation is None:\n",
        "            # send basis coefficients\n",
        "            others_basis_coeffs_encoder = th.cat(\n",
        "                [self.all_clients_basis_coeffs_encoder[i] for i in range(self.num_clients) if i != client.id], dim=1)\n",
        "            if self.all_clients_basis_coeffs_decoder is None:\n",
        "                others_basis_coeffs_decoder = None\n",
        "            else:\n",
        "                others_basis_coeffs_decoder = th.cat(\n",
        "                    [self.all_clients_basis_coeffs_decoder[i] for i in range(self.num_clients) if i != client.id],\n",
        "                    dim=0)\n",
        "            client.set_others_basis_coeffs(others_basis_coeffs_encoder, others_basis_coeffs_decoder)\n",
        "\n",
        "    def aggregate_model(self, clients: list[Client], client_weights: Optional[list[float]] = None) -> None:\n",
        "        # aggregate state_dict_encoder and state_dict_decoder\n",
        "        # here we just apply FedAvg to state_dict_encoder and state_dict_decoder\n",
        "        state_dict_encoder_list = [client.encoder.state_dict() for client in clients]\n",
        "        state_dict_decoder_list = [client.decoder.state_dict() for client in clients]\n",
        "        client_weights = [1.0 / len(clients) for _ in range(len(clients))] if client_weights is None else client_weights\n",
        "        # take care of the missing keys due to different schemas across clients\n",
        "        for key in self.state_dict_encoder:\n",
        "            total_weight = 0\n",
        "            aggregated_param = 0\n",
        "            for state_dict_encoder, client_weight in zip(state_dict_encoder_list, client_weights):\n",
        "                if key in state_dict_encoder:\n",
        "                    aggregated_param += state_dict_encoder[key] * client_weight\n",
        "                    total_weight += client_weight\n",
        "            self.state_dict_encoder[key] = aggregated_param / total_weight\n",
        "        for key in self.state_dict_decoder:\n",
        "            total_weight = 0\n",
        "            aggregated_param = 0\n",
        "            for state_dict_decoder, client_weight in zip(state_dict_decoder_list, client_weights):\n",
        "                if key in state_dict_decoder:\n",
        "                    aggregated_param += state_dict_decoder[key] * client_weight\n",
        "                    total_weight += client_weight\n",
        "            self.state_dict_decoder[key] = aggregated_param / total_weight\n",
        "\n",
        "        if self.ablation is None:\n",
        "            # update basis coefficients at server\n",
        "            # need to detach()\n",
        "            for client in clients:\n",
        "                self.all_clients_basis_coeffs_encoder[client.id] = th.stack(\n",
        "                    [th.stack([param.detach() for param in param_dict.values()]) for param_dict in\n",
        "                     client.encoder.basis_coeffs_encoder])\n",
        "                if self.all_clients_basis_coeffs_decoder is not None:\n",
        "                    self.all_clients_basis_coeffs_decoder[client.id] = th.stack(\n",
        "                        [param.detach() for param in client.decoder.basis_coeffs_decoder.values()], dim=0)\n",
        "\n",
        "\n",
        "class FedHGN:\n",
        "    def __init__(self, args: Namespace) -> None:\n",
        "        self.max_rounds = args.max_rounds\n",
        "        self.num_clients = args.num_clients\n",
        "        self.fraction = args.fraction\n",
        "        self.task = args.task\n",
        "        self.val_interval = args.val_interval\n",
        "        self.patience = args.patience\n",
        "        self.save_path = args.save_path\n",
        "        self.ablation = args.ablation\n",
        "\n",
        "        if self.task == \"node_classification\":\n",
        "            # data preparation for all clients\n",
        "            g_list, out_dim, train_nid_dict_list, val_nid_dict_list, test_nid_dict_list = load_data(args)\n",
        "            # align schemas (for ablation)\n",
        "            ntypes, etypes, canonical_etypes = align_schemas(g_list)\n",
        "            # setup clients\n",
        "            self.clients = [\n",
        "                Client(args, (g_list[i], out_dim, train_nid_dict_list[i], val_nid_dict_list[i], test_nid_dict_list[i]),\n",
        "                       i) for i in range(self.num_clients)]\n",
        "            # setup a server\n",
        "            self.server = Server(args, ntypes, etypes, canonical_etypes, out_dim)\n",
        "            # client weights for updates and evaluation metrics\n",
        "            self.train_client_weights = [sum([len(nids) for nids in nid_dict.values()]) for nid_dict in\n",
        "                                         train_nid_dict_list]\n",
        "            train_num_samples = sum(self.train_client_weights)\n",
        "            self.train_client_weights = [weight / train_num_samples for weight in self.train_client_weights]\n",
        "            self.val_client_weights = [sum([len(nids) for nids in nid_dict.values()]) for nid_dict in val_nid_dict_list]\n",
        "            val_num_samples = sum(self.val_client_weights)\n",
        "            self.val_client_weights = [weight / val_num_samples for weight in self.val_client_weights]\n",
        "            self.test_client_weights = [sum([len(nids) for nids in nid_dict.values()]) for nid_dict in\n",
        "                                        test_nid_dict_list]\n",
        "            test_num_samples = sum(self.test_client_weights)\n",
        "            self.test_client_weights = [weight / test_num_samples for weight in self.test_client_weights]\n",
        "        else:\n",
        "            raise ValueError(\"Unknown task: {}\".format(self.task))\n",
        "\n",
        "    def train(self) -> None:\n",
        "        sample_size = max(round(self.fraction * self.num_clients), 1)\n",
        "        early_stopping = EarlyStopping(patience=self.patience, mode=\"score\", save_path=self.save_path, verbose=True)\n",
        "        with tqdm.tqdm(range(self.max_rounds), desc=\"FedHGN\") as tq:\n",
        "            for round_no in tq:\n",
        "                # randomly select clients\n",
        "                selected_clients = random.sample(self.clients, sample_size)\n",
        "                # server sends model to clients\n",
        "                for client in selected_clients:\n",
        "                    self.server.send_model(client)\n",
        "                # clients train on their local data (local update)\n",
        "                round_loss = 0\n",
        "                for client in selected_clients:\n",
        "                    client_loss = client.local_update()\n",
        "                    round_loss += client_loss\n",
        "                round_loss /= sample_size\n",
        "                # server aggregates model updates from clients\n",
        "                selected_clients_weights = [self.train_client_weights[client.id] for client in selected_clients]\n",
        "                total_weight = sum(selected_clients_weights)\n",
        "                selected_clients_weights = [weight / total_weight for weight in selected_clients_weights]\n",
        "                self.server.aggregate_model(selected_clients, selected_clients_weights)\n",
        "\n",
        "                tq.set_postfix({\"round-loss\": f\"{round_loss:.4f}\"}, refresh=False)\n",
        "\n",
        "                # validation and early stopping\n",
        "                if (round_no + 1) % self.val_interval == 0:\n",
        "                    val_results = self.evaluate(is_test=False)\n",
        "                    print_info = {key: f\"{value:.4f}\" for key, value in val_results.items()}\n",
        "                    tq.set_postfix(print_info, refresh=False)\n",
        "                    if self.task == \"node_classification\":\n",
        "                        # quantity = (val_results[\"macro-f1\"] + val_results[\"micro-f1\"]) / 2\n",
        "                        quantity = val_results[\"accuracy\"]\n",
        "                    else:\n",
        "                        raise ValueError(\"Unknown task: {}\".format(self.task))\n",
        "                    early_stopping(quantity, callback=self.save_checkpoint)\n",
        "                    if early_stopping.early_stop:\n",
        "                        print(\"Early stopping\")\n",
        "                        break\n",
        "\n",
        "    def evaluate(self, is_test: bool = False) -> dict[str, float]:\n",
        "        # send the latest model to all clients\n",
        "        for client in self.clients:\n",
        "            self.server.send_model(client)\n",
        "        # get client weights\n",
        "        client_weights = self.test_client_weights if is_test else self.val_client_weights\n",
        "        # clients evaluate on their local data\n",
        "        avg_results = defaultdict(float)\n",
        "        for i, (client, weight) in enumerate(zip(self.clients, client_weights)):\n",
        "            client_results = client.local_evaluate(is_test)\n",
        "\n",
        "            # Tambahan: print per client\n",
        "            print(f\"Client {i} Evaluation ({'Test' if is_test else 'Validation'}):\")\n",
        "            print_results(client_results)\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            for k, v in client_results.items():\n",
        "                avg_results[k] += v * weight\n",
        "        return dict(avg_results)\n",
        "\n",
        "\n",
        "\n",
        "    def save_checkpoint(self, save_path: str) -> None:\n",
        "        save_path = Path(save_path)\n",
        "        save_path.mkdir(parents=True, exist_ok=True)\n",
        "        # save server model\n",
        "        th.save(self.server.state_dict_encoder, save_path / \"server_encoder.pt\")\n",
        "        th.save(self.server.state_dict_decoder, save_path / \"server_decoder.pt\")\n",
        "        if self.ablation is None:\n",
        "            th.save(self.server.all_clients_basis_coeffs_encoder, save_path / \"all_clients_basis_coeffs_encoder.pt\")\n",
        "            th.save(self.server.all_clients_basis_coeffs_decoder, save_path / \"all_clients_basis_coeffs_decoder.pt\")\n",
        "        # save clients model\n",
        "        for i, client in enumerate(self.clients):\n",
        "            th.save(client.encoder.state_dict(), save_path / f\"client_{i}_encoder.pt\")\n",
        "            th.save(client.decoder.state_dict(), save_path / f\"client_{i}_decoder.pt\")\n",
        "\n",
        "    def load_checkpoint(self, load_path: str) -> None:\n",
        "        load_path = Path(load_path)\n",
        "        # load server model\n",
        "        self.server.state_dict_encoder = th.load(load_path / \"server_encoder.pt\")\n",
        "        self.server.state_dict_decoder = th.load(load_path / \"server_decoder.pt\")\n",
        "        if self.ablation is None:\n",
        "            self.server.all_clients_basis_coeffs_encoder = th.load(load_path / \"all_clients_basis_coeffs_encoder.pt\")\n",
        "            self.server.all_clients_basis_coeffs_decoder = th.load(load_path / \"all_clients_basis_coeffs_decoder.pt\")\n",
        "        # load clients model\n",
        "        for i, client in enumerate(self.clients):\n",
        "            client.encoder.load_state_dict(th.load(load_path / f\"client_{i}_encoder.pt\"))\n",
        "            client.decoder.load_state_dict(th.load(load_path / f\"client_{i}_decoder.pt\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "W9ajTi9rd11R"
      },
      "outputs": [],
      "source": [
        "def main(args):\n",
        "    global fl_framework  # <-- tambahkan ini supaya bisa diakses dari luar\n",
        "\n",
        "    if args.framework == \"FedHGN\":\n",
        "        fl_framework = FedHGN(args)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown framework.\")\n",
        "\n",
        "    evaluate_local_models_individually(fl_framework.clients)\n",
        "    fl_framework.train()\n",
        "    fl_framework.load_checkpoint(args.save_path)\n",
        "    avg_results = fl_framework.evaluate(is_test=True)\n",
        "    print_results(avg_results)\n",
        "    save_results(avg_results, args.save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "l9Ma5O-KfvoG"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")  # Nonaktifkan semua warning Python\n",
        "os.environ['DGL_WARNINGS'] = '0'   # Nonaktifkan warning dari DGL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "egLrITvGcds7"
      },
      "outputs": [],
      "source": [
        "# !pip install numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3bpKuEddALZ",
        "outputId": "1bf6c6eb-0240-404c-ae28-bac1bac08eec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Local Evaluation (Before Fed Training)\n",
            "Client 0 initial evaluation:\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.3274\t0.3274\t0.2744\n",
            "----------------------------------------\n",
            "Client 1 initial evaluation:\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9225\t0.9225\t0.4892\n",
            "----------------------------------------\n",
            "Client 2 initial evaluation:\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.7557\t0.7557\t0.4685\n",
            "----------------------------------------\n",
            "Client 3 initial evaluation:\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.8261\t0.8261\t0.4783\n",
            "----------------------------------------\n",
            "Client 4 initial evaluation:\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9447\t0.9447\t0.4858\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FedHGN:   0%|          | 0/1000 [00:00<?, ?it/s]\n",
            "Client 3:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 3:  33%|      | 1/3 [00:00<00:01,  1.63it/s, epoch-loss=0.6375]\u001b[A\n",
            "Client 3:  67%|   | 2/3 [00:01<00:00,  1.61it/s, epoch-loss=0.5598]\u001b[A\n",
            "Client 3: 100%|| 3/3 [00:02<00:00,  1.41it/s, epoch-loss=0.5155]\n",
            "\n",
            "Client 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 0:  33%|      | 1/3 [00:00<00:01,  1.06it/s, epoch-loss=0.6999]\u001b[A\n",
            "Client 0:  67%|   | 2/3 [00:01<00:00,  1.06it/s, epoch-loss=0.5543]\u001b[A\n",
            "Client 0: 100%|| 3/3 [00:02<00:00,  1.17it/s, epoch-loss=0.4999]\n",
            "\n",
            "Client 1:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 1:  33%|      | 1/3 [00:00<00:01,  1.65it/s, epoch-loss=0.6805]\u001b[A\n",
            "Client 1:  67%|   | 2/3 [00:01<00:00,  1.64it/s, epoch-loss=0.5479]\u001b[A\n",
            "Client 1: 100%|| 3/3 [00:01<00:00,  1.61it/s, epoch-loss=0.4935]\n",
            "\n",
            "Client 2:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 2:  33%|      | 1/3 [00:00<00:01,  1.64it/s, epoch-loss=0.6598]\u001b[A\n",
            "Client 2:  67%|   | 2/3 [00:01<00:00,  1.66it/s, epoch-loss=0.5351]\u001b[A\n",
            "Client 2: 100%|| 3/3 [00:01<00:00,  1.63it/s, epoch-loss=0.4823]\n",
            "\n",
            "Client 4:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 4:  33%|      | 1/3 [00:00<00:01,  1.74it/s, epoch-loss=0.6765]\u001b[A\n",
            "Client 4:  67%|   | 2/3 [00:01<00:00,  1.67it/s, epoch-loss=0.5339]\u001b[A\n",
            "Client 4: 100%|| 3/3 [00:01<00:00,  1.68it/s, epoch-loss=0.4763]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 0 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9649\t0.9649\t0.4911\n",
            "----------------------------------------\n",
            "Client 1 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9695\t0.9695\t0.4923\n",
            "----------------------------------------\n",
            "Client 2 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9723\t0.9723\t0.4930\n",
            "----------------------------------------\n",
            "Client 3 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9639\t0.9639\t0.4908\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rFedHGN:   0%|          | 1/1000 [00:12<3:29:23, 12.58s/it, accuracy=0.9719, micro-f1=0.9719, macro-f1=0.4929]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 4 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9895\t0.9895\t0.4974\n",
            "----------------------------------------\n",
            "Validation score increased (-inf --> 0.971892).  Saving model ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Client 3:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 3:  33%|      | 1/3 [00:00<00:01,  1.64it/s, epoch-loss=0.5063]\u001b[A\n",
            "Client 3:  67%|   | 2/3 [00:01<00:00,  1.62it/s, epoch-loss=0.4736]\u001b[A\n",
            "Client 3: 100%|| 3/3 [00:01<00:00,  1.61it/s, epoch-loss=0.4452]\n",
            "\n",
            "Client 1:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 1:  33%|      | 1/3 [00:00<00:01,  1.10it/s, epoch-loss=0.5041]\u001b[A\n",
            "Client 1:  67%|   | 2/3 [00:01<00:00,  1.04it/s, epoch-loss=0.4622]\u001b[A\n",
            "Client 1: 100%|| 3/3 [00:02<00:00,  1.06it/s, epoch-loss=0.4282]\n",
            "\n",
            "Client 2:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 2:  33%|      | 1/3 [00:00<00:01,  1.67it/s, epoch-loss=0.4944]\u001b[A\n",
            "Client 2:  67%|   | 2/3 [00:01<00:00,  1.62it/s, epoch-loss=0.4536]\u001b[A\n",
            "Client 2: 100%|| 3/3 [00:01<00:00,  1.62it/s, epoch-loss=0.4204]\n",
            "\n",
            "Client 4:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 4:  33%|      | 1/3 [00:00<00:01,  1.75it/s, epoch-loss=0.4937]\u001b[A\n",
            "Client 4:  67%|   | 2/3 [00:01<00:00,  1.67it/s, epoch-loss=0.4495]\u001b[A\n",
            "Client 4: 100%|| 3/3 [00:01<00:00,  1.68it/s, epoch-loss=0.4132]\n",
            "\n",
            "Client 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 0:  33%|      | 1/3 [00:00<00:01,  1.71it/s, epoch-loss=0.5244]\u001b[A\n",
            "Client 0:  67%|   | 2/3 [00:01<00:00,  1.72it/s, epoch-loss=0.4802]\u001b[A\n",
            "Client 0: 100%|| 3/3 [00:01<00:00,  1.67it/s, epoch-loss=0.4464]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 0 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9649\t0.9649\t0.4911\n",
            "----------------------------------------\n",
            "Client 1 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9695\t0.9695\t0.4923\n",
            "----------------------------------------\n",
            "Client 2 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9723\t0.9723\t0.4930\n",
            "----------------------------------------\n",
            "Client 3 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9639\t0.9639\t0.4908\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rFedHGN:   0%|          | 2/1000 [00:25<3:28:11, 12.52s/it, accuracy=0.9719, micro-f1=0.9719, macro-f1=0.4929]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 4 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9895\t0.9895\t0.4974\n",
            "----------------------------------------\n",
            "EarlyStopping counter: 1 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Client 1:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 1:  33%|      | 1/3 [00:00<00:01,  1.69it/s, epoch-loss=0.4151]\u001b[A\n",
            "Client 1:  67%|   | 2/3 [00:01<00:00,  1.63it/s, epoch-loss=0.3875]\u001b[A\n",
            "Client 1: 100%|| 3/3 [00:01<00:00,  1.66it/s, epoch-loss=0.3632]\n",
            "\n",
            "Client 4:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 4:  33%|      | 1/3 [00:00<00:01,  1.62it/s, epoch-loss=0.4072]\u001b[A\n",
            "Client 4:  67%|   | 2/3 [00:01<00:00,  1.30it/s, epoch-loss=0.3764]\u001b[A\n",
            "Client 4: 100%|| 3/3 [00:02<00:00,  1.22it/s, epoch-loss=0.3495]\n",
            "\n",
            "Client 3:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 3:  33%|      | 1/3 [00:00<00:01,  1.11it/s, epoch-loss=0.4306]\u001b[A\n",
            "Client 3:  67%|   | 2/3 [00:01<00:00,  1.36it/s, epoch-loss=0.4062]\u001b[A\n",
            "Client 3: 100%|| 3/3 [00:02<00:00,  1.43it/s, epoch-loss=0.3843]\n",
            "\n",
            "Client 2:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 2:  33%|      | 1/3 [00:00<00:01,  1.67it/s, epoch-loss=0.4088]\u001b[A\n",
            "Client 2:  67%|   | 2/3 [00:01<00:00,  1.65it/s, epoch-loss=0.3811]\u001b[A\n",
            "Client 2: 100%|| 3/3 [00:01<00:00,  1.62it/s, epoch-loss=0.3566]\n",
            "\n",
            "Client 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 0:  33%|      | 1/3 [00:00<00:01,  1.74it/s, epoch-loss=0.4412]\u001b[A\n",
            "Client 0:  67%|   | 2/3 [00:01<00:00,  1.69it/s, epoch-loss=0.4119]\u001b[A\n",
            "Client 0: 100%|| 3/3 [00:01<00:00,  1.70it/s, epoch-loss=0.3872]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 0 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9649\t0.9649\t0.4911\n",
            "----------------------------------------\n",
            "Client 1 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9695\t0.9695\t0.4923\n",
            "----------------------------------------\n",
            "Client 2 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9723\t0.9723\t0.4930\n",
            "----------------------------------------\n",
            "Client 3 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9639\t0.9639\t0.4908\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rFedHGN:   0%|          | 3/1000 [00:37<3:26:39, 12.44s/it, accuracy=0.9719, micro-f1=0.9719, macro-f1=0.4929]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 4 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9895\t0.9895\t0.4974\n",
            "----------------------------------------\n",
            "EarlyStopping counter: 2 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Client 2:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 2:  33%|      | 1/3 [00:00<00:01,  1.68it/s, epoch-loss=0.3450]\u001b[A\n",
            "Client 2:  67%|   | 2/3 [00:01<00:00,  1.60it/s, epoch-loss=0.3242]\u001b[A\n",
            "Client 2: 100%|| 3/3 [00:01<00:00,  1.61it/s, epoch-loss=0.3054]\n",
            "\n",
            "Client 1:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 1:  33%|      | 1/3 [00:00<00:01,  1.60it/s, epoch-loss=0.3506]\u001b[A\n",
            "Client 1:  67%|   | 2/3 [00:01<00:00,  1.51it/s, epoch-loss=0.3304]\u001b[A\n",
            "Client 1: 100%|| 3/3 [00:02<00:00,  1.33it/s, epoch-loss=0.3122]\n",
            "\n",
            "Client 3:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 3:  33%|      | 1/3 [00:00<00:01,  1.11it/s, epoch-loss=0.3739]\u001b[A\n",
            "Client 3:  67%|   | 2/3 [00:01<00:00,  1.07it/s, epoch-loss=0.3547]\u001b[A\n",
            "Client 3: 100%|| 3/3 [00:02<00:00,  1.19it/s, epoch-loss=0.3374]\n",
            "\n",
            "Client 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 0:  33%|      | 1/3 [00:00<00:01,  1.77it/s, epoch-loss=0.3791]\u001b[A\n",
            "Client 0:  67%|   | 2/3 [00:01<00:00,  1.66it/s, epoch-loss=0.3575]\u001b[A\n",
            "Client 0: 100%|| 3/3 [00:01<00:00,  1.65it/s, epoch-loss=0.3385]\n",
            "\n",
            "Client 4:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 4:  33%|      | 1/3 [00:00<00:01,  1.73it/s, epoch-loss=0.3441]\u001b[A\n",
            "Client 4:  67%|   | 2/3 [00:01<00:00,  1.66it/s, epoch-loss=0.3206]\u001b[A\n",
            "Client 4: 100%|| 3/3 [00:01<00:00,  1.65it/s, epoch-loss=0.2995]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 0 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9649\t0.9649\t0.4911\n",
            "----------------------------------------\n",
            "Client 1 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9695\t0.9695\t0.4923\n",
            "----------------------------------------\n",
            "Client 2 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9723\t0.9723\t0.4930\n",
            "----------------------------------------\n",
            "Client 3 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9639\t0.9639\t0.4908\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rFedHGN:   0%|          | 4/1000 [00:50<3:28:00, 12.53s/it, accuracy=0.9719, micro-f1=0.9719, macro-f1=0.4929]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 4 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9895\t0.9895\t0.4974\n",
            "----------------------------------------\n",
            "EarlyStopping counter: 3 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Client 3:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 3:  33%|      | 1/3 [00:00<00:01,  1.79it/s, epoch-loss=0.3302]\u001b[A\n",
            "Client 3:  67%|   | 2/3 [00:01<00:00,  1.71it/s, epoch-loss=0.3150]\u001b[A\n",
            "Client 3: 100%|| 3/3 [00:01<00:00,  1.69it/s, epoch-loss=0.3012]\n",
            "\n",
            "Client 1:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 1:  33%|      | 1/3 [00:00<00:01,  1.68it/s, epoch-loss=0.3019]\u001b[A\n",
            "Client 1:  67%|   | 2/3 [00:01<00:00,  1.65it/s, epoch-loss=0.2867]\u001b[A\n",
            "Client 1: 100%|| 3/3 [00:01<00:00,  1.54it/s, epoch-loss=0.2729]\n",
            "\n",
            "Client 4:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 4:  33%|      | 1/3 [00:00<00:01,  1.16it/s, epoch-loss=0.2956]\u001b[A\n",
            "Client 4:  67%|   | 2/3 [00:01<00:00,  1.08it/s, epoch-loss=0.2767]\u001b[A\n",
            "Client 4: 100%|| 3/3 [00:02<00:00,  1.08it/s, epoch-loss=0.2595]\n",
            "\n",
            "Client 2:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 2:  33%|      | 1/3 [00:00<00:01,  1.63it/s, epoch-loss=0.2960]\u001b[A\n",
            "Client 2:  67%|   | 2/3 [00:01<00:00,  1.60it/s, epoch-loss=0.2800]\u001b[A\n",
            "Client 2: 100%|| 3/3 [00:01<00:00,  1.60it/s, epoch-loss=0.2656]\n",
            "\n",
            "Client 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 0:  33%|      | 1/3 [00:00<00:01,  1.79it/s, epoch-loss=0.3301]\u001b[A\n",
            "Client 0:  67%|   | 2/3 [00:01<00:00,  1.71it/s, epoch-loss=0.3132]\u001b[A\n",
            "Client 0: 100%|| 3/3 [00:01<00:00,  1.69it/s, epoch-loss=0.2981]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 0 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9649\t0.9649\t0.4911\n",
            "----------------------------------------\n",
            "Client 1 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9695\t0.9695\t0.4923\n",
            "----------------------------------------\n",
            "Client 2 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9723\t0.9723\t0.4930\n",
            "----------------------------------------\n",
            "Client 3 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9639\t0.9639\t0.4908\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rFedHGN:   0%|          | 5/1000 [01:02<3:27:20, 12.50s/it, accuracy=0.9719, micro-f1=0.9719, macro-f1=0.4929]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 4 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9895\t0.9895\t0.4974\n",
            "----------------------------------------\n",
            "EarlyStopping counter: 4 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Client 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 0:  33%|      | 1/3 [00:00<00:01,  1.69it/s, epoch-loss=0.2903]\u001b[A\n",
            "Client 0:  67%|   | 2/3 [00:01<00:00,  1.70it/s, epoch-loss=0.2770]\u001b[A\n",
            "Client 0: 100%|| 3/3 [00:01<00:00,  1.65it/s, epoch-loss=0.2651]\n",
            "\n",
            "Client 3:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 3:  33%|      | 1/3 [00:00<00:01,  1.76it/s, epoch-loss=0.2962]\u001b[A\n",
            "Client 3:  67%|   | 2/3 [00:01<00:00,  1.68it/s, epoch-loss=0.2842]\u001b[A\n",
            "Client 3: 100%|| 3/3 [00:01<00:00,  1.67it/s, epoch-loss=0.2732]\n",
            "\n",
            "Client 2:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 2:  33%|      | 1/3 [00:00<00:01,  1.55it/s, epoch-loss=0.2581]\u001b[A\n",
            "Client 2:  67%|   | 2/3 [00:01<00:00,  1.32it/s, epoch-loss=0.2458]\u001b[A\n",
            "Client 2: 100%|| 3/3 [00:02<00:00,  1.20it/s, epoch-loss=0.2348]\n",
            "\n",
            "Client 4:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 4:  33%|      | 1/3 [00:00<00:01,  1.11it/s, epoch-loss=0.2575]\u001b[A\n",
            "Client 4:  67%|   | 2/3 [00:01<00:00,  1.33it/s, epoch-loss=0.2418]\u001b[A\n",
            "Client 4: 100%|| 3/3 [00:02<00:00,  1.39it/s, epoch-loss=0.2274]\n",
            "\n",
            "Client 1:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 1:  33%|      | 1/3 [00:00<00:01,  1.68it/s, epoch-loss=0.2647]\u001b[A\n",
            "Client 1:  67%|   | 2/3 [00:01<00:00,  1.64it/s, epoch-loss=0.2531]\u001b[A\n",
            "Client 1: 100%|| 3/3 [00:01<00:00,  1.65it/s, epoch-loss=0.2428]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 0 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9649\t0.9649\t0.4911\n",
            "----------------------------------------\n",
            "Client 1 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9695\t0.9695\t0.4923\n",
            "----------------------------------------\n",
            "Client 2 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9723\t0.9723\t0.4930\n",
            "----------------------------------------\n",
            "Client 3 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9639\t0.9639\t0.4908\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rFedHGN:   1%|          | 6/1000 [01:15<3:27:10, 12.51s/it, accuracy=0.9719, micro-f1=0.9719, macro-f1=0.4929]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 4 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9895\t0.9895\t0.4974\n",
            "----------------------------------------\n",
            "EarlyStopping counter: 5 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Client 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 0:  33%|      | 1/3 [00:00<00:01,  1.68it/s, epoch-loss=0.2582]\u001b[A\n",
            "Client 0:  67%|   | 2/3 [00:01<00:00,  1.60it/s, epoch-loss=0.2479]\u001b[A\n",
            "Client 0: 100%|| 3/3 [00:01<00:00,  1.60it/s, epoch-loss=0.2387]\n",
            "\n",
            "Client 2:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 2:  33%|      | 1/3 [00:00<00:01,  1.69it/s, epoch-loss=0.2288]\u001b[A\n",
            "Client 2:  67%|   | 2/3 [00:01<00:00,  1.66it/s, epoch-loss=0.2195]\u001b[A\n",
            "Client 2: 100%|| 3/3 [00:01<00:00,  1.65it/s, epoch-loss=0.2113]\n",
            "\n",
            "Client 4:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 4:  33%|      | 1/3 [00:00<00:01,  1.75it/s, epoch-loss=0.2270]\u001b[A\n",
            "Client 4:  67%|   | 2/3 [00:01<00:00,  1.63it/s, epoch-loss=0.2136]\u001b[A\n",
            "Client 4: 100%|| 3/3 [00:02<00:00,  1.45it/s, epoch-loss=0.2014]\n",
            "\n",
            "Client 1:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 1:  33%|      | 1/3 [00:00<00:01,  1.03it/s, epoch-loss=0.2360]\u001b[A\n",
            "Client 1:  67%|   | 2/3 [00:01<00:00,  1.05it/s, epoch-loss=0.2274]\u001b[A\n",
            "Client 1: 100%|| 3/3 [00:02<00:00,  1.18it/s, epoch-loss=0.2197]\n",
            "\n",
            "Client 3:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 3:  33%|      | 1/3 [00:00<00:01,  1.74it/s, epoch-loss=0.2697]\u001b[A\n",
            "Client 3:  67%|   | 2/3 [00:01<00:00,  1.70it/s, epoch-loss=0.2601]\u001b[A\n",
            "Client 3: 100%|| 3/3 [00:01<00:00,  1.72it/s, epoch-loss=0.2514]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 0 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9649\t0.9649\t0.4911\n",
            "----------------------------------------\n",
            "Client 1 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9695\t0.9695\t0.4923\n",
            "----------------------------------------\n",
            "Client 2 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9723\t0.9723\t0.4930\n",
            "----------------------------------------\n",
            "Client 3 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9639\t0.9639\t0.4908\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rFedHGN:   1%|          | 7/1000 [01:27<3:26:28, 12.48s/it, accuracy=0.9719, micro-f1=0.9719, macro-f1=0.4929]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 4 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9895\t0.9895\t0.4974\n",
            "----------------------------------------\n",
            "EarlyStopping counter: 6 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Client 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 0:  33%|      | 1/3 [00:00<00:01,  1.70it/s, epoch-loss=0.2329]\u001b[A\n",
            "Client 0:  67%|   | 2/3 [00:01<00:00,  1.67it/s, epoch-loss=0.2251]\u001b[A\n",
            "Client 0: 100%|| 3/3 [00:01<00:00,  1.69it/s, epoch-loss=0.2182]\n",
            "\n",
            "Client 2:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 2:  33%|      | 1/3 [00:00<00:01,  1.66it/s, epoch-loss=0.2063]\u001b[A\n",
            "Client 2:  67%|   | 2/3 [00:01<00:00,  1.64it/s, epoch-loss=0.1994]\u001b[A\n",
            "Client 2: 100%|| 3/3 [00:01<00:00,  1.62it/s, epoch-loss=0.1933]\n",
            "\n",
            "Client 4:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 4:  33%|      | 1/3 [00:00<00:01,  1.73it/s, epoch-loss=0.2023]\u001b[A\n",
            "Client 4:  67%|   | 2/3 [00:01<00:00,  1.65it/s, epoch-loss=0.1909]\u001b[A\n",
            "Client 4: 100%|| 3/3 [00:01<00:00,  1.62it/s, epoch-loss=0.1805]\n",
            "\n",
            "Client 1:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 1:  33%|      | 1/3 [00:00<00:01,  1.18it/s, epoch-loss=0.2142]\u001b[A\n",
            "Client 1:  67%|   | 2/3 [00:01<00:00,  1.09it/s, epoch-loss=0.2079]\u001b[A\n",
            "Client 1: 100%|| 3/3 [00:02<00:00,  1.10it/s, epoch-loss=0.2022]\n",
            "\n",
            "Client 3:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 3:  33%|      | 1/3 [00:00<00:01,  1.42it/s, epoch-loss=0.2489]\u001b[A\n",
            "Client 3:  67%|   | 2/3 [00:01<00:00,  1.55it/s, epoch-loss=0.2412]\u001b[A\n",
            "Client 3: 100%|| 3/3 [00:01<00:00,  1.55it/s, epoch-loss=0.2342]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 0 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9649\t0.9649\t0.4911\n",
            "----------------------------------------\n",
            "Client 1 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9695\t0.9695\t0.4923\n",
            "----------------------------------------\n",
            "Client 2 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9723\t0.9723\t0.4930\n",
            "----------------------------------------\n",
            "Client 3 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9639\t0.9639\t0.4908\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rFedHGN:   1%|          | 8/1000 [01:39<3:26:25, 12.49s/it, accuracy=0.9719, micro-f1=0.9719, macro-f1=0.4929]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 4 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9895\t0.9895\t0.4974\n",
            "----------------------------------------\n",
            "EarlyStopping counter: 7 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Client 4:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 4:  33%|      | 1/3 [00:00<00:01,  1.76it/s, epoch-loss=0.1823]\u001b[A\n",
            "Client 4:  67%|   | 2/3 [00:01<00:00,  1.69it/s, epoch-loss=0.1725]\u001b[A\n",
            "Client 4: 100%|| 3/3 [00:01<00:00,  1.65it/s, epoch-loss=0.1636]\n",
            "\n",
            "Client 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 0:  33%|      | 1/3 [00:00<00:01,  1.76it/s, epoch-loss=0.2135]\u001b[A\n",
            "Client 0:  67%|   | 2/3 [00:01<00:00,  1.67it/s, epoch-loss=0.2077]\u001b[A\n",
            "Client 0: 100%|| 3/3 [00:01<00:00,  1.69it/s, epoch-loss=0.2027]\n",
            "\n",
            "Client 3:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 3:  33%|      | 1/3 [00:00<00:01,  1.60it/s, epoch-loss=0.2325]\u001b[A\n",
            "Client 3:  67%|   | 2/3 [00:01<00:00,  1.63it/s, epoch-loss=0.2263]\u001b[A\n",
            "Client 3: 100%|| 3/3 [00:01<00:00,  1.65it/s, epoch-loss=0.2207]\n",
            "\n",
            "Client 1:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 1:  33%|      | 1/3 [00:00<00:01,  1.62it/s, epoch-loss=0.1978]\u001b[A\n",
            "Client 1:  67%|   | 2/3 [00:01<00:00,  1.28it/s, epoch-loss=0.1932]\u001b[A\n",
            "Client 1: 100%|| 3/3 [00:02<00:00,  1.22it/s, epoch-loss=0.1891]\n",
            "\n",
            "Client 2:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 2:  33%|      | 1/3 [00:00<00:01,  1.09it/s, epoch-loss=0.1893]\u001b[A\n",
            "Client 2:  67%|   | 2/3 [00:01<00:00,  1.15it/s, epoch-loss=0.1843]\u001b[A\n",
            "Client 2: 100%|| 3/3 [00:02<00:00,  1.25it/s, epoch-loss=0.1798]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 0 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9649\t0.9649\t0.4911\n",
            "----------------------------------------\n",
            "Client 1 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9695\t0.9695\t0.4923\n",
            "----------------------------------------\n",
            "Client 2 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9723\t0.9723\t0.4930\n",
            "----------------------------------------\n",
            "Client 3 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9639\t0.9639\t0.4908\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rFedHGN:   1%|          | 9/1000 [01:52<3:27:00, 12.53s/it, accuracy=0.9719, micro-f1=0.9719, macro-f1=0.4929]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 4 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9895\t0.9895\t0.4974\n",
            "----------------------------------------\n",
            "EarlyStopping counter: 8 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Client 2:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 2:  33%|      | 1/3 [00:00<00:01,  1.71it/s, epoch-loss=0.1766]\u001b[A\n",
            "Client 2:  67%|   | 2/3 [00:01<00:00,  1.64it/s, epoch-loss=0.1730]\u001b[A\n",
            "Client 2: 100%|| 3/3 [00:01<00:00,  1.63it/s, epoch-loss=0.1697]\n",
            "\n",
            "Client 1:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 1:  33%|      | 1/3 [00:00<00:01,  1.75it/s, epoch-loss=0.1856]\u001b[A\n",
            "Client 1:  67%|   | 2/3 [00:01<00:00,  1.64it/s, epoch-loss=0.1822]\u001b[A\n",
            "Client 1: 100%|| 3/3 [00:01<00:00,  1.63it/s, epoch-loss=0.1793]\n",
            "\n",
            "Client 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 0:  33%|      | 1/3 [00:00<00:01,  1.63it/s, epoch-loss=0.1989]\u001b[A\n",
            "Client 0:  67%|   | 2/3 [00:01<00:00,  1.65it/s, epoch-loss=0.1947]\u001b[A\n",
            "Client 0: 100%|| 3/3 [00:01<00:00,  1.64it/s, epoch-loss=0.1911]\n",
            "\n",
            "Client 3:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 3:  33%|      | 1/3 [00:00<00:01,  1.70it/s, epoch-loss=0.2195]\u001b[A\n",
            "Client 3:  67%|   | 2/3 [00:01<00:00,  1.65it/s, epoch-loss=0.2145]\u001b[A\n",
            "Client 3: 100%|| 3/3 [00:02<00:00,  1.42it/s, epoch-loss=0.2099]\n",
            "\n",
            "Client 4:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 4:  33%|      | 1/3 [00:01<00:02,  1.00s/it, epoch-loss=0.1660]\u001b[A\n",
            "Client 4:  67%|   | 2/3 [00:01<00:00,  1.02it/s, epoch-loss=0.1576]\u001b[A\n",
            "Client 4: 100%|| 3/3 [00:02<00:00,  1.14it/s, epoch-loss=0.1500]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 0 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9649\t0.9649\t0.4911\n",
            "----------------------------------------\n",
            "Client 1 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9695\t0.9695\t0.4923\n",
            "----------------------------------------\n",
            "Client 2 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9723\t0.9723\t0.4930\n",
            "----------------------------------------\n",
            "Client 3 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9639\t0.9639\t0.4908\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rFedHGN:   1%|          | 10/1000 [02:05<3:27:31, 12.58s/it, accuracy=0.9719, micro-f1=0.9719, macro-f1=0.4929]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 4 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9895\t0.9895\t0.4974\n",
            "----------------------------------------\n",
            "EarlyStopping counter: 9 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Client 0:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 0:  33%|      | 1/3 [00:00<00:01,  1.77it/s, epoch-loss=0.1882]\u001b[A\n",
            "Client 0:  67%|   | 2/3 [00:01<00:00,  1.67it/s, epoch-loss=0.1853]\u001b[A\n",
            "Client 0: 100%|| 3/3 [00:01<00:00,  1.66it/s, epoch-loss=0.1828]\n",
            "\n",
            "Client 2:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 2:  33%|      | 1/3 [00:00<00:01,  1.52it/s, epoch-loss=0.1671]\u001b[A\n",
            "Client 2:  67%|   | 2/3 [00:01<00:00,  1.47it/s, epoch-loss=0.1645]\u001b[A\n",
            "Client 2: 100%|| 3/3 [00:02<00:00,  1.47it/s, epoch-loss=0.1622]\n",
            "\n",
            "Client 1:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 1:  33%|      | 1/3 [00:00<00:01,  1.46it/s, epoch-loss=0.1765]\u001b[A\n",
            "Client 1:  67%|   | 2/3 [00:01<00:00,  1.39it/s, epoch-loss=0.1741]\u001b[A\n",
            "Client 1: 100%|| 3/3 [00:02<00:00,  1.36it/s, epoch-loss=0.1721]\n",
            "\n",
            "Client 3:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 3:  33%|      | 1/3 [00:00<00:01,  1.35it/s, epoch-loss=0.2092]\u001b[A\n",
            "Client 3:  67%|   | 2/3 [00:01<00:00,  1.14it/s, epoch-loss=0.2051]\u001b[A\n",
            "Client 3: 100%|| 3/3 [00:02<00:00,  1.08it/s, epoch-loss=0.2015]\n",
            "\n",
            "Client 4:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
            "Client 4:  33%|      | 1/3 [00:00<00:01,  1.08it/s, epoch-loss=0.1527]\u001b[A\n",
            "Client 4:  67%|   | 2/3 [00:01<00:00,  1.11it/s, epoch-loss=0.1455]\u001b[A\n",
            "Client 4: 100%|| 3/3 [00:02<00:00,  1.22it/s, epoch-loss=0.1390]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 0 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9649\t0.9649\t0.4911\n",
            "----------------------------------------\n",
            "Client 1 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9695\t0.9695\t0.4923\n",
            "----------------------------------------\n",
            "Client 2 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9723\t0.9723\t0.4930\n",
            "----------------------------------------\n",
            "Client 3 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9639\t0.9639\t0.4908\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rFedHGN:   1%|          | 10/1000 [02:19<3:49:22, 13.90s/it, accuracy=0.9719, micro-f1=0.9719, macro-f1=0.4929]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 4 Evaluation (Validation):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9895\t0.9895\t0.4974\n",
            "----------------------------------------\n",
            "EarlyStopping counter: 10 out of 10\n",
            "Early stopping\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Client 0 Evaluation (Test):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9653\t0.9653\t0.4912\n",
            "----------------------------------------\n",
            "Client 1 Evaluation (Test):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9694\t0.9694\t0.4922\n",
            "----------------------------------------\n",
            "Client 2 Evaluation (Test):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9721\t0.9721\t0.4929\n",
            "----------------------------------------\n",
            "Client 3 Evaluation (Test):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9639\t0.9639\t0.4908\n",
            "----------------------------------------\n",
            "Client 4 Evaluation (Test):\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9895\t0.9895\t0.4974\n",
            "----------------------------------------\n",
            "accuracy\tmicro-f1\tmacro-f1\n",
            "0.9719\t0.9719\t0.4929\n"
          ]
        }
      ],
      "source": [
        "import torch as th\n",
        "from types import SimpleNamespace\n",
        "\n",
        "# Isi konfigurasi secara manual (ganti sesuai kebutuhan)\n",
        "args = SimpleNamespace()\n",
        "args.dataset = \"AML\"\n",
        "args.split_strategy = \"edges\"\n",
        "args.framework = \"FedHGN\"  # Bisa juga: FedAvg, FedProx, Local, Central\n",
        "args.ablation = None       # Atau: \"B\", \"C\", \"B+C\"\n",
        "args.model = \"RGCN\"\n",
        "args.num_clients = 5\n",
        "args.gpu = -1\n",
        "args.random_seed = 1000\n",
        "args.config_path = \"configs.yaml\"  # Pastikan sesuai path file kamu di Colab\n",
        "\n",
        "# Load config dan inisialisasi device\n",
        "args = load_configs(args)\n",
        "args.device = th.device(f\"cuda\" if args.gpu >= 0 and th.cuda.is_available() else \"cpu\")\n",
        "args.save_path = get_save_path(args)\n",
        "\n",
        "# Set random seed untuk reprodusibilitas\n",
        "set_random_seeds(args.random_seed)\n",
        "\n",
        "# Jalankan federated learning\n",
        "main(args)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}